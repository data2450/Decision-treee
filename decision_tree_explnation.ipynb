{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "decision tree explnation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP96Su6khOxeseW2oRtUSOh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/data2450/Decision-treee/blob/main/decision_tree_explnation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxWDAQZjX4qG"
      },
      "source": [
        "A decision tree is a flowchart-like structure in which each internal node represents a test on a feature (e.g. whether a coin flip comes up heads or tails)\n",
        "\n",
        "\n",
        "each leaf node represents a class label (decision taken after computing all features) and branches represent conjunctions of features that lead to those class labels. The paths from root to leaf represent classification rules. Below diagram illustrate the basic flow of decision tree for decision making with labels (Rain(Yes), No Rain(No)).\n",
        "\n",
        "Decision trees are constructed via an algorithmic approach that identifies ways to split a data set based on different conditions. It is one of the most widely used and practical methods for supervised learning. Decision Trees are a non-parametric supervised learning method used for both classification and regression tasks.\n",
        "\n",
        "\n",
        "\n",
        "# **Information Gain**\n",
        "\n",
        "Information gain is used to decide which feature to split on at each step in building the tree. Simplicity is best, so we want to keep our tree small. To do so, at each step we should choose the split that results in the purest daughter nodes. A commonly used measure of purity is called information. For each node of the tree, the information value measures **how much information a feature gives us about the class**. **The split with the highest information gain will be taken as the first split and the process will continue until all children nodes are pure, or until the information gain is 0**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xftH05gHZHC2"
      },
      "source": [
        "# Gini Impurity\n",
        "\n",
        "**Pure**\n",
        "Pure means, in a selected sample of dataset all data belongs to same class (PURE).\n",
        "\n",
        "\n",
        "**Impure**\n",
        "Impure means, data is mixture of different classes.\n",
        "\n",
        "**Definition of Gini Impurity**:\n",
        "Gini Impurity is a measurement of the **likelihood of an incorrect classification of a new instance of a random variable, if that new instance were randomly classified according to the distribution of class labels from the data set**.\n",
        "If our dataset is Pure then likelihood of incorrect classification is 0. If our sample is mixture of different classes then likelihood of incorrect classification will be high.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQaCuMUTbN2N"
      },
      "source": [
        " **criterion**; The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgARsgXBbcKz"
      },
      "source": [
        "criterion is used to find the best split ,we have two methods gini and entropy ,in gini we use gini Impurity and in entropy we use information gain,both these some probablity measurment to find the best split "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpdvYjILeEtb"
      },
      "source": [
        "# What is Entropy?\n",
        "\n",
        "Entropy is the measurement of impurities or randomness in the data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxnd3gjQX1AM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}